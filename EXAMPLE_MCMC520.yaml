timing: True
debug: False
stop_at_error: False

likelihood:
  sn.pantheon:
    path: ./external_modules/data/sn_data
  bao.sixdf_2011_bao:
    path: ./external_modules/data/
  bao.sdss_dr7_mgs:
    path: ./external_modules/data/
  bao.sdss_dr12_consensus_bao:
    path: ./external_modules/data/
  lsst_y1.lsst_emu_cs_lcdm:
    emu_file: "./projects/lsst_y1/emulator_output/models/FINAL/model_1"
    data_vector_file: "./projects/lsst_y1/data/example4_lsst_y1_theory.modelvector"
    mask_file: "./projects/lsst_y1/data/lsst_3x2_linear.mask" #dv is also generated with linear mask
    n_dim: 13 

params:
  logA:
    prior:
      min: 2.83321
      max: 3.21888
    ref:
      dist: norm
      loc: 3.0448
      scale: 0.15
    proposal: 0.15
    latex: \log(10^{10} A_\mathrm{s})
    # drop: true
  As:
    value: 'lambda logA: 1e-10*np.exp(logA)'
    latex: A_\mathrm{s}
  ns:
    prior:
      min: 0.92
      max: 1.00
    ref:
      dist: norm
      loc: 0.96605
      scale: 0.01
    proposal: 0.01
    latex: n_\mathrm{s}
  H0:
    prior:
      min: 61
      max: 73
    ref:
      dist: norm
      loc: 67.32
      scale: 5
    proposal: 3
    latex: H_0
  omegabh2:
    prior:
      dist: norm
      loc: 0.02208 
      scale: 0.00052
    ref:
      dist: norm
      loc: 0.022383
      scale: 0.005
    proposal: 0.005
    latex: \Omega_\mathrm{b} h^2
  omegach2:
    prior:
      min: 0.06
      max: 0.45
    ref:
      dist: norm
      loc: 0.12011
      scale: 0.03
    proposal: 0.03
    latex: \Omega_\mathrm{c} h^2
  mnu:
    value: 0.06
  tau:
    value: 0.05
    latex: \tau_\mathrm{reio}
  omegal:
    latex: \Omega_\Lambda
  # As_1e9:
  #   derived: 'lambda As: 1e9*As'
  #   latex: 10^9 A_\mathrm{s}
  omegam:
    latex: \Omega_\mathrm{m}
  omegamh2:
    derived: 'lambda omegam, H0: omegam*(H0/100)**2'
    latex: \Omega_\mathrm{m} h^2
  omegab:
    derived: 'lambda omegabh2, H0: omegabh2/((H0/100)**2)'
    latex: \Omega_\mathrm{b}
  omegac:
    derived: 'lambda omegach2, H0: omegach2/((H0/100)**2)'
    latex: \Omega_\mathrm{c}
  omegan2:
    latex: \Omega_\mathrm{\\nu} h^2
  omegan:
    derived: 'lambda omegan2, H0: omegan2/((H0/100)**2)'
    latex: \Omega_\mathrm{\\nu}
  sigma8:
    latex: \sigma_8
  s8h5:
    derived: 'lambda sigma8, H0: sigma8*(H0*1e-2)**(-0.5)'
    latex: \sigma_8/h^{0.5}
  s8omegamp5:
    derived: 'lambda sigma8, omegam: sigma8*omegam**0.5'
    latex: \sigma_8 \Omega_\mathrm{m}^{0.5}
  s8omegamp25:
    derived: 'lambda sigma8, omegam: sigma8*omegam**0.25'
    latex: \sigma_8 \Omega_\mathrm{m}^{0.25}
  s8:
    derived: 'lambda sigma8, omegam: sigma8*(omegam/0.3)**0.5'
    latex: \sigma_8 \Omega_\mathrm{m/0.3}^{0.5}
  LSST_BARYON_Q1:
    value: 0.0
    latex: Q1_\mathrm{LSST}^1
  LSST_BARYON_Q2:
    value: 0.0
    latex: Q2_\mathrm{LSST}^2
  w:
    value: -1
    latex: w0
  w_growth:
    value: -1
    latex: w_\mathrm{growth}
  omegam_growth:
    prior:
      min: 0.24
      max: 0.4
    ref:
      dist: norm
      loc: 0.3
      scale: 0.01
    proposal: 0.01
    latex: \Omega_\mathrm{m}^\mathrm{growth}

theory:
  camb:
    path: ./external_modules/code/CAMB
    stop_at_error: False
    use_renames: True
    extra_args:
      halofit_version: takahashi
      AccuracyBoost: 1.15
      lens_potential_accuracy: 1.0
      num_massive_neutrinos: 1
      nnu: 3.046
      dark_energy_model: ppf
      accurate_massive_neutrino_transfers: false
      k_per_logint: 20

sampler:
  mcmc:
    # ---------------------------------------------------------------------
    # File (w/ path) or matrix defining a covariance matrix for the proposal:
    # - null (default): will be generated from params info (prior and proposal)
    # - matrix: remember to set `covmat_params` to the parameters in the matrix
    covmat: "./projects/lsst_y1/EXAMPLE_MCMC520.covmat"
    covmat_params:
    # --------------------------------------
    # --------------------------------------
    # Proposal covariance matrix learning
    # --------------------------------------
    # --------------------------------------
    learn_proposal: True
    # Don't learn if convergence better than...
    learn_proposal_Rminus1_min: 0.03
    # (even earlier if a param is not in the given covariance matrix)
    learn_proposal_Rminus1_max_early: 2000.
    # --------------------------------------
    # --------------------------------------
    # Convergence and stopping
    # --------------------------------------
    # --------------------------------------
    # Maximum number of posterior evaluations
    max_samples: .inf
    # Gelman-Rubin R-1 on means
    Rminus1_stop: 0.02
    # Gelman-Rubin R-1 on std deviations
    Rminus1_cl_stop: 0.2
    Rminus1_cl_level: 0.95
    # --------------------------------------
    # --------------------------------------
    # Exploiting speed hierarchy
    # --------------------------------------
    # --------------------------------------
    measure_speeds: False
    drag: False
    oversample_power: 0.6
    oversample_thin: True
    blocking:
      - [1,
          [
            logA, ns, H0, omegabh2, omegach2
          ]
        ]
      - [2,
          [
            LSST_DZ_S1, LSST_DZ_S2, LSST_DZ_S3, LSST_DZ_S4, LSST_DZ_S5, LSST_A1_1, LSST_A1_2, 
            omegam_growth
          ]
        ]
      - [25,
          [
            LSST_M1, LSST_M2, LSST_M3, LSST_M4, LSST_M5
          ]
        ]
    # --------------------------------------
    # --------------------------------------
    # Avoid chain getting suck forever
    # --------------------------------------
    # --------------------------------------
    max_tries: 100000 # longer than usual
    burn_in: 0
    # ---------------------------------------------------------------------
    # ---------------------------------------------------------------------
    # When no MPI used, number of fractions of the chain to compare
    # ---------------------------------------------------------------------
    # ---------------------------------------------------------------------
    Rminus1_single_split: 4

output: ./projects/lsst_y1/chains/EXAMPLE_MCMC520
